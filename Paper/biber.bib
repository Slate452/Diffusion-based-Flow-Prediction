@article{Wang2024,
   abstract = {Flow field prediction is essential for airfoil design. It is a time-consuming task to obtain the flow fields around an airfoil. Convolution neural networks (CNN) have been applied for flow field prediction in recent years. However, CNN-based methods rely heavily on convolutional kernels to process information within local neighborhoods, making it difficult to capture global information. In this paper, we propose a novel self-attention generative network referred to as SAG-FlowNet, both for original and optimization airfoil flow field prediction. We investigate the self-attention mechanism with a multi-layer convolutional generative network. We use the self-attention module to capture various information within and between flow fields, and with the help of the attention module, the CNN can utilize the information with stronger relationships regardless of their distances to achieve better flow field prediction results. Through extensive experiments, we explore the proposed SAG-FlowNet performance. The experimental results show that the method has accurate and universal performance for the reconstruction and prediction of the flow field both for original and optimized airfoils. SAG-FlowNet is promising for fast flow field prediction and has potential applications in accelerating airfoil design.},
   author = {Xiao Wang and Yi Jiang and Guanxiong Li and Laiping Zhang and Xiaogang Deng},
   doi = {10.1007/s00500-023-09602-x},
   issn = {14337479},
   journal = {Soft Computing},
   keywords = {Flow field,Generative networks,Prediction,Self-attention},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Sag-flownet: self-attention generative network for airfoil flow field prediction},
   year = {2024},
}
@article{Lusch2018,
   abstract = {Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear has the potential to enable nonlinear prediction, estimation, and control using linear theory. The Koopman operator is a leading data-driven embedding, and its eigenfunctions provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven challenging. This work leverages deep learning to discover representations of Koopman eigenfunctions from data. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold. We identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems with continuous spectra. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding, while connecting our models to decades of asymptotics. Thus, we benefit from the power of deep learning, while retaining the physical interpretability of Koopman embeddings.},
   author = {Bethany Lusch and J. Nathan Kutz and Steven L. Brunton},
   doi = {10.1038/s41467-018-07210-0},
   issn = {20411723},
   issue = {1},
   journal = {Nature Communications},
   month = {12},
   pmid = {30470743},
   publisher = {Nature Publishing Group},
   title = {Deep learning for universal linear embeddings of nonlinear dynamics},
   volume = {9},
   year = {2018},
}
@article{Fukami2019,
   abstract = {We use machine learning to perform super-resolution analysis of grossly under-resolved turbulent flow field data to reconstruct the high-resolution flow field. Two machine learning models are developed, namely, the convolutional neural network (CNN) and the hybrid downsampled skip-connection/multi-scale (DSC/MS) models. These machine learning models are applied to a two-dimensional cylinder wake as a preliminary test and show remarkable ability to reconstruct laminar flow from low-resolution flow field data. We further assess the performance of these models for two-dimensional homogeneous turbulence. The CNN and DSC/MS models are found to reconstruct turbulent flows from extremely coarse flow field images with remarkable accuracy. For the turbulent flow problem, the machine-leaning-based super-resolution analysis can greatly enhance the spatial resolution with as little as 50 training snapshot data, holding great potential to reveal subgrid-scale physics of complex turbulent flows. With the growing availability of flow field data from high-fidelity simulations and experiments, the present approach motivates the development of effective super-resolution models for a variety of fluid flows.},
   author = {Kai Fukami and Koji Fukagata and Kunihiko Taira},
   doi = {10.1017/jfm.2019.238},
   issn = {14697645},
   journal = {Journal of Fluid Mechanics},
   keywords = {Computational methods,Homogeneous turbulence,Wakes},
   month = {7},
   pages = {106-120},
   publisher = {Cambridge University Press},
   title = {Super-resolution reconstruction of turbulent flows with machine learning},
   volume = {870},
   year = {2019},
}
@article{Ling2016,
   abstract = {There exists significant demand for improved Reynolds-Averaged Navier-Stokes (RANS) turbulence models that are informed by and can represent a richer set of turbulence physics. This paper presents a method of using deep neural networks to learn a model for the Reynolds stress anisotropy tensor from high-fidelity simulation data. A novel neural network architecture is proposed which uses a multiplicative layer with an invariant tensor basis to embed Galilean invariance into the predicted anisotropy tensor. It is demonstrated that this neural network architecture provides improved prediction accuracy compared with a generic neural network architecture that does not embed this invariance property. The Reynolds stress anisotropy predictions of this invariant neural network are propagated through to the velocity field for two test cases. For both test cases, significant improvement versus baseline RANS linear eddy viscosity and nonlinear eddy viscosity models is demonstrated.},
   author = {Julia Ling and Andrew Kurzawski and Jeremy Templeton},
   doi = {10.1017/jfm.2016.615},
   issn = {14697645},
   journal = {Journal of Fluid Mechanics},
   keywords = {turbulence modelling,turbulence theory,turbulent flows},
   month = {11},
   pages = {155-166},
   publisher = {Cambridge University Press},
   title = {Reynolds averaged turbulence modelling using deep neural networks with embedded invariance},
   volume = {807},
   year = {2016},
}
@article{Raissi2019,
   abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
   author = {M. Raissi and P. Perdikaris and G. E. Karniadakis},
   doi = {10.1016/j.jcp.2018.10.045},
   issn = {10902716},
   journal = {Journal of Computational Physics},
   keywords = {Data-driven scientific computing,Machine learning,Nonlinear dynamics,Predictive modeling,Runge–Kutta methods},
   month = {2},
   pages = {686-707},
   publisher = {Academic Press Inc.},
   title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
   volume = {378},
   year = {2019},
}
@article{Bruni2024,
   abstract = {Deep learning methods have seen a wide range of successful applications across different industries. Up until now, applications to physical simulations such as computational fluid dynamics (CFD) have been limited to simple test cases of minor industrial relevance. This article demonstrates the development of a novel deep learning framework for real-time predictions of the impact of manufacturing and build variations on the flow field and overall performance of axial compressors in gas turbines, with a focus on tip clearance variations. The scatter in compressor efficiency associated with manufacturing and build variations can significantly increase the <inline-formula><tex-math notation="LaTeX">$CO_\{2\}$</tex-math></inline-formula> emissions, thus being of great industrial and environmental relevance. The proposed <italic>C(NN)FD</italic> architecture achieves real-time accuracy comparable to the CFD benchmark. Predicting the flow field and using it to calculate the corresponding overall performance renders the methodology generalizable, while filtering only relevant parts of the CFD solution makes the methodology scalable to industrial applications.},
   author = {Giuseppe Bruni and Sepehr Maleki and Senthil K. Krishnababu},
   doi = {10.1109/TII.2024.3393140},
   issn = {19410050},
   journal = {IEEE Transactions on Industrial Informatics},
   keywords = {Aerodynamics,Blades,Compressors,Computational modeling,Deep learning,Manufacturing,Predictive models,axial compressor,computational fluid dynamics (CFD),convolutional neural network (CNN),deep learning,gas turbine},
   publisher = {IEEE Computer Society},
   title = {C(NN)FD - A Deep Learning Framework for Turbomachinery CFD Analysis},
   year = {2024},
}
@article{Duru2022,
   abstract = {Learning from data offers new opportunities for developing computational methods in research fields, such as fluid dynamics, which constantly accumulate a large amount of data. This study presents a deep learning approach for the transonic flow field predictions around airfoils. The physics of transonic flow is integrated into the neural network model by utilizing Reynolds-averaged Navier–Stokes (RANS) simulations. A detailed investigation on the performance of the model is made both qualitatively and quantitatively. The flow features associated with the transonic effects and the angle of attack variation, such as the shock waves and the flow separation, are well predicted. Furthermore, predicted flowfield data are used to compute the aerodynamic coefficients. The findings indicate that the presented model may allow avoiding time-consuming computational fluid dynamics (CFD) simulations, especially in the design optimization studies with a slight loss of accuracy.},
   author = {Cihat Duru and Hande Alemdar and Ozgur Ugras Baran},
   doi = {10.1016/j.compfluid.2022.105312},
   issn = {00457930},
   journal = {Computers and Fluids},
   keywords = {Airfoil aerodynamics,Deep learning,Shock waves,Transonic flow},
   month = {3},
   publisher = {Elsevier Ltd},
   title = {A deep learning approach for the transonic flow field predictions around airfoils},
   volume = {236},
   year = {2022},
}
@article{Chen2023,
   abstract = {The present study investigates the accurate inference of Reynolds-averaged Navier–Stokes solutions for the two-dimensional compressible flow over aerofoils with a deep neural network. Our approach yields networks that learn to generate precise flow fields for varying body-fitted, structured grids by providing them with an encoding of the corresponding mapping to a canonical space for the solutions. We apply the deep neural network model to a benchmark case of incompressible flow at randomly given angles of attack and Reynolds numbers and achieve an improvement of more than an order of magnitude compared to previous work. Further, for transonic flow cases, the deep neural network model accurately predicts complex flow behavior at high Reynolds numbers, such as shock wave/boundary layer interaction, and quantitative distributions like pressure coefficient, skin friction coefficient as well as wake total pressure profiles downstream of aerofoils. The proposed deep learning method significantly speeds up the predictions of flow fields and shows promise for enabling fast aerodynamic designs.},
   author = {Li Wei Chen and Nils Thuerey},
   doi = {10.1016/j.compfluid.2022.105707},
   issn = {00457930},
   journal = {Computers and Fluids},
   keywords = {Deep learning,Neural network,Transonic flow},
   month = {1},
   publisher = {Elsevier Ltd},
   title = {Towards high-accuracy deep learning inference of compressible flows over aerofoils},
   volume = {250},
   year = {2023},
}
@article{Duru2022,
   abstract = {Learning from data offers new opportunities for developing computational methods in research fields, such as fluid dynamics, which constantly accumulate a large amount of data. This study presents a deep learning approach for the transonic flow field predictions around airfoils. The physics of transonic flow is integrated into the neural network model by utilizing Reynolds-averaged Navier–Stokes (RANS) simulations. A detailed investigation on the performance of the model is made both qualitatively and quantitatively. The flow features associated with the transonic effects and the angle of attack variation, such as the shock waves and the flow separation, are well predicted. Furthermore, predicted flowfield data are used to compute the aerodynamic coefficients. The findings indicate that the presented model may allow avoiding time-consuming computational fluid dynamics (CFD) simulations, especially in the design optimization studies with a slight loss of accuracy.},
   author = {Cihat Duru and Hande Alemdar and Ozgur Ugras Baran},
   doi = {10.1016/j.compfluid.2022.105312},
   issn = {00457930},
   journal = {Computers and Fluids},
   keywords = {Airfoil aerodynamics,Deep learning,Shock waves,Transonic flow},
   month = {3},
   publisher = {Elsevier Ltd},
   title = {A deep learning approach for the transonic flow field predictions around airfoils},
   volume = {236},
   year = {2022},
}
@article{WU2022,
   abstract = {Deep learning has been probed for the airfoil performance prediction in recent years. Compared with the expensive CFD simulations and wind tunnel experiments, deep learning models can be leveraged to somewhat mitigate such expenses with proper means. Nevertheless, effective training of the data-driven models in deep learning severely hinges on the data in diversity and quantity. In this paper, we present a novel data augmented Generative Adversarial Network (GAN), daGAN, for rapid and accurate flow filed prediction, allowing the adaption to the task with sparse data. The presented approach consists of two modules, pre-training module and fine-tuning module. The pre-training module utilizes a conditional GAN (cGAN) to preliminarily estimate the distribution of the training data. In the fine-tuning module, we propose a novel adversarial architecture with two generators one of which fulfils a promising data augmentation operation, so that the complement data is adequately incorporated to boost the generalization of the model. We use numerical simulation data to verify the generalization of daGAN on airfoils and flow conditions with sparse training data. The results show that daGAN is a promising tool for rapid and accurate evaluation of detailed flow field without the requirement for big training data.},
   author = {Haizhou WU and Xuejun LIU and Wei AN and Hongqiang LYU},
   doi = {10.1016/j.cja.2021.02.012},
   issn = {10009361},
   issue = {1},
   journal = {Chinese Journal of Aeronautics},
   keywords = {CFD,Flow field,Generative adversarial networks (GANs),Sparse data,Supercritical airfoil},
   month = {1},
   pages = {470-484},
   publisher = {Elsevier B.V.},
   title = {A generative deep learning framework for airfoil flow field prediction with sparse data},
   volume = {35},
   year = {2022},
}
@article{Dai2023,
   abstract = {An efficient data-driven approach for predicting steady airfoil flows is proposed based on the Fourier neural operator (FNO), which is a new framework of neural networks. Theoretical reasons and experimental results are provided to support the necessity and effectiveness of the improvements made to the FNO, which involve using an additional branch neural operator to approximate the contribution of boundary conditions to steady solutions. The proposed approach runs several orders of magnitude faster than the traditional numerical methods. The predictions for flows around airfoils and ellipses demonstrate the superior accuracy and impressive speed of this novel approach. Furthermore, the property of zero-shot super-resolution enables the proposed approach to overcome the limitations of predicting airfoil flows with Cartesian grids, thereby improving the accuracy in the near-wall region. There is no doubt that the unprecedented speed and accuracy in forecasting steady airfoil flows have massive benefits for airfoil design and optimization.},
   author = {Yuanjun Dai and Yiran An and Zhi Li and Jihua Zhang and Chao Yu},
   doi = {10.1007/s10483-023-3050-9},
   issn = {15732754},
   issue = {11},
   journal = {Applied Mathematics and Mechanics (English Edition)},
   keywords = {Fourier neural operator (FNO),O368,deep learning (DL),steady airfoil flow},
   month = {11},
   pages = {2019-2038},
   publisher = {Springer Science and Business Media B.V.},
   title = {Fourier neural operator with boundary conditions for efficient prediction of steady airfoil flows},
   volume = {44},
   year = {2023},
}
@article{Zuo2024,
   abstract = {Computational Fluid Dynamics (CFD) has become an indispensable tool in the optimization design, and evaluation of aircraft aerodynamics. However, solving the Navier-Stokes (NS) equations is a time-consuming, memory demanding and computationally expensive task. Artificial intelligence offers a promising avenue for flow field solving. In this work, we propose a novel deep learning framework for rapidly reconstructing airfoil flow fields. Channel attention and spatial attention modules are utilized in the downsampling stage of the UNet to enhance the feature learning capabilities of the deep learning model. Additionally, Embedding the predicted values of the deep learning model as initial values into the CFD solver to accelerate its iterative convergence. The NACA series airfoils were used to validate the prediction accuracy and generalization of the deep learning model. The experimental results represent the deep learning model achieving flow field prediction speed three orders of magnitude faster than CFD solver. Furthermore, the CFD solver integrated with deep learning model demonstrates a threefold acceleration compared to CFD solver. By extensively mining historical flow field data, an efficient solution is derived for the rapid simulation of aircraft flow fields.},
   author = {Kuijun Zuo and Zhengyin Ye and Shuhui Bu and Xianxu Yuan and Weiwei Zhang},
   doi = {10.1016/j.ast.2024.109207},
   issn = {12709638},
   journal = {Aerospace Science and Technology},
   keywords = {Airfoil aerodynamics,Deep learning,Flow field prediction,PHengLEI},
   month = {7},
   publisher = {Elsevier Masson s.r.l.},
   title = {Fast simulation of airfoil flow field via deep neural network},
   volume = {150},
   year = {2024},
}
@article{,
   title = {S0045793022000068},
}
@article{Thuerey2018,
   abstract = {With this study we investigate the accuracy of deep learning models for the inference of Reynolds-Averaged Navier-Stokes solutions. We focus on a modernized U-net architecture, and evaluate a large number of trained neural networks with respect to their accuracy for the calculation of pressure and velocity distributions. In particular, we illustrate how training data size and the number of weights influence the accuracy of the solutions. With our best models we arrive at a mean relative pressure and velocity error of less than 3% across a range of previously unseen airfoil shapes. In addition all source code is publicly available in order to ensure reproducibility and to provide a starting point for researchers interested in deep learning methods for physics problems. While this work focuses on RANS solutions, the neural network architecture and learning setup are very generic, and applicable to a wide range of PDE boundary value problems on Cartesian grids.},
   author = {Nils Thuerey and Konstantin Weissenow and Lukas Prantl and Xiangyu Hu},
   doi = {10.2514/1.j058291},
   month = {10},
   title = {Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations of Airfoil Flows},
   url = {http://arxiv.org/abs/1810.08217 http://dx.doi.org/10.2514/1.j058291},
   year = {2018},
}
@article{Bruni2023,
   abstract = {Application of deep learning methods to physical simulations such as CFD (Computational Fluid Dynamics) for turbomachinery applications, have been so far of limited industrial relevance. This paper demonstrates the development and application of a deep learning framework for real-time predictions of the impact of manufacturing and build variations, such as tip clearance and surface roughness, on the flow field and aerodynamic performance of multi-stage axial compressors in gas turbines. The associated scatter in compressor efficiency is known to have a significant impact on the corresponding overall performance and emissions of the gas turbine, therefore posing a challenge of great industrial and environmental relevance. The proposed architecture is proven to achieve an accuracy comparable to that of the CFD benchmark, in real-time, for an industrially relevant application. The deployed model, is readily integrated within the manufacturing and build process of gas turbines, thus providing the opportunity to analytically assess the impact on performance and potentially reduce requirements for expensive physical tests.},
   author = {Giuseppe Bruni and Sepehr Maleki and Senthil K. Krishnababu},
   month = {10},
   title = {Deep learning modelling of manufacturing and build variations on multi-stage axial compressors aerodynamics},
   url = {http://arxiv.org/abs/2310.04264},
   year = {2023},
}
@article{Liu2023,
   abstract = {Leveraging neural networks as surrogate models for turbulence simulation is a topic of growing interest. At the same time, embodying the inherent uncertainty of simulations in the predictions of surrogate models remains very challenging. The present study makes a first attempt to use denoising diffusion probabilistic models (DDPMs) to train an uncertainty-aware surrogate model for turbulence simulations. Due to its prevalence, the simulation of flows around airfoils with various shapes, Reynolds numbers, and angles of attack is chosen as the learning objective. Our results show that DDPMs can successfully capture the whole distribution of solutions and, as a consequence, accurately estimate the uncertainty of the simulations. The performance of DDPMs is also compared with varying baselines in the form of Bayesian neural networks and heteroscedastic models. Experiments demonstrate that DDPMs outperform the other methods regarding a variety of accuracy metrics. Besides, it offers the advantage of providing access to the complete distributions of uncertainties rather than providing a set of parameters. As such, it can yield realistic and detailed samples from the distribution of solutions.},
   author = {Qiang Liu and Nils Thuerey},
   month = {12},
   title = {Uncertainty-aware Surrogate Models for Airfoil Flow Simulations with Denoising Diffusion Probabilistic Models},
   url = {http://arxiv.org/abs/2312.05320},
   year = {2023},
}
@article{,
   title = {dl},
}
@misc{,
   abstract = {The heavy-duty gas turbine is playing an increasingly significant role on power generation due to its lower-emission, higher flexibility and thermo-efficiency. Main subsystems of the gas turbine like compressor, combustor and turbine degrade over the operating time under the harsh environmental conditions, which largely impacts the efficiency and productivity of the system. Therefore, it is critical to develop effective approaches to monitor performance degradation of a heavy-duty gas turbine for system predictive maintenance thus improving the efficiency and productivity of the machine. This paper presents a new physics informed machine learning methodology to predict the degradation of gas turbine by seamlessly integrating thermodynamic heat balancing mechanism, component characteristics, multi-source data and artificial neural network model. The mechanism-based thermodynamic model is established for multiple subsystems considering the balance of flow, mass and energy, and then integrated to a system level for performance simulation of the gas turbine under different conditions. The system model is able to effectively simulate values for those parameters that are not measurable (e.g. GT exhaust flow) or inaccurately measured (e.g. fuel flow). Machine learning based data cleaning approach is employed to preprocess the multivariate raw data of the gas turbine. The difference between design performance data and corrected value obtained from the physics-informed model under ISO conditions is utilized to assess the performance degradation. A Long Short-Term Memory (LSTM) model is established from the fusion of the actual and simulation data to predict the performance degradation of the gas turbine. A comparison study with the classical Nonlinear Autoregressive Network with External Input (NARX) neural network is conducted to demonstrate the advantage of the proposed method.},
   author = {Yiyang Liu and Xiaomo Jiang and Xin Ge and Manman Wei},
   keywords = {Key Word: Gas Turbine,LSTM,Machine Learning,Performance Degradation Predict,Thermodynamic Balance},
   title = {A Physics Informed Machine Learning Approach for Performance Degradation Monitoring of Gas Turbine},
}
@article{Hong2022,
   abstract = {Denoising diffusion models (DDMs) have attracted attention for their exceptional generation quality and diversity. This success is largely attributed to the use of class- or text-conditional diffusion guidance methods, such as classifier and classifier-free guidance. In this paper, we present a more comprehensive perspective that goes beyond the traditional guidance methods. From this generalized perspective, we introduce novel condition- and training-free strategies to enhance the quality of generated images. As a simple solution, blur guidance improves the suitability of intermediate samples for their fine-scale information and structures, enabling diffusion models to generate higher quality samples with a moderate guidance scale. Improving upon this, Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy. Specifically, SAG adversarially blurs only the regions that diffusion models attend to at each iteration and guides them accordingly. Our experimental results show that our SAG improves the performance of various diffusion models, including ADM, IDDPM, Stable Diffusion, and DiT. Moreover, combining SAG with conventional guidance methods leads to further improvement.},
   author = {Susung Hong and Gyuseong Lee and Wooseok Jang and Seungryong Kim},
   month = {10},
   title = {Improving Sample Quality of Diffusion Models Using Self-Attention Guidance},
   url = {http://arxiv.org/abs/2210.00939},
   year = {2022},
}
@article{Vaswani2017,
   abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
   author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
   month = {6},
   title = {Attention Is All You Need},
   url = {http://arxiv.org/abs/1706.03762},
   year = {2017},
}
@article{Ho2020,
   abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
   author = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
   month = {6},
   title = {Denoising Diffusion Probabilistic Models},
   url = {http://arxiv.org/abs/2006.11239},
   year = {2020},
}
@article{Kim2021,
   abstract = {Knowledge distillation (KD), transferring knowledge from a cumbersome teacher model to a lightweight student model, has been investigated to design efficient neural architectures. Generally, the objective function of KD is the Kullback-Leibler (KL) divergence loss between the softened probability distributions of the teacher model and the student model with the temperature scaling hyperparameter tau. Despite its widespread use, few studies have discussed the influence of such softening on generalization. Here, we theoretically show that the KL divergence loss focuses on the logit matching when tau increases and the label matching when tau goes to 0 and empirically show that the logit matching is positively correlated to performance improvement in general. From this observation, we consider an intuitive KD loss function, the mean squared error (MSE) between the logit vectors, so that the student model can directly learn the logit of the teacher model. The MSE loss outperforms the KL divergence loss, explained by the difference in the penultimate layer representations between the two losses. Furthermore, we show that sequential distillation can improve performance and that KD, particularly when using the KL divergence loss with small tau, mitigates the label noise. The code to reproduce the experiments is publicly available online at https://github.com/jhoon-oh/kd_data/.},
   author = {Taehyeon Kim and Jaehoon Oh and NakYil Kim and Sangwook Cho and Se-Young Yun},
   month = {5},
   title = {Comparing Kullback-Leibler Divergence and Mean Squared Error Loss in Knowledge Distillation},
   url = {http://arxiv.org/abs/2105.08919},
   year = {2021},
}
